{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimxs74/adsl/blob/main/Experimen_Present_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5df160e-f282-4812-92b5-c33f2b082b72"
      },
      "source": [
        "# **Sentinel-1 and Sentinel-2 data fusion through Deep Learning**\n",
        "![](imgs/fusion_paradigms.png)"
      ],
      "id": "b5df160e-f282-4812-92b5-c33f2b082b72"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4be3f9c3-2e08-46bc-9778-321b3a855b89"
      },
      "source": [
        "**To re-train the models set the *TRAIN* flaf to *True*.**\n",
        "\n",
        "**If *TRAIN = False* pre-trained weights will be loaded.**"
      ],
      "id": "4be3f9c3-2e08-46bc-9778-321b3a855b89"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48d8146f-4bed-44a9-91ab-a166f839b27e"
      },
      "source": [
        "Ambil dataset\n",
        "\n",
        "Reference : https://github.com/wkentaro/gdown\n",
        "\n",
        "source code : https://github.com/Sebbyraft/S1-S2-DataFusion"
      ],
      "id": "48d8146f-4bed-44a9-91ab-a166f839b27e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K5aLMf5eoguT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8101e9e4-0e6d-4dfd-e59c-74f6bc7cfb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "K5aLMf5eoguT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFuUNY9zHesM"
      },
      "source": [
        "Download dataset dengan jumlah file cukup banyak dan besar"
      ],
      "id": "SFuUNY9zHesM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrghIRFKBo56"
      },
      "outputs": [],
      "source": [
        "# Tugas 1 : Jumlah dataset awal\n",
        "# !unzip \"/content/drive/MyDrive/400. COM_SCIE/465. Analisis data spasial lanjut/adsl research/S1-S2-DataFusion/dataset_zip.zip\" > /dev/null\n",
        "\n",
        "# Jumlah dataset awal diptimasi 50 pic /class\n",
        " !unzip \"/content/drive/MyDrive/400. COM_SCIE/465. Analisis data spasial lanjut/adsl research/S1-S2-DataFusion/dataset_zip.zip\" > /dev/null"
      ],
      "id": "nrghIRFKBo56"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BI83G32E0kE8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "deb0461c-612a-4223-ef10-6319c7cb01ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BY_YU4GvG8HFMfXgldeVx0aDTch0lhv5\n",
            "To: /content/CNN_Classifier.py\n",
            "100%|██████████| 2.79k/2.79k [00:00<00:00, 5.09MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BtSUZ6sZJze1uO-lMZ07jp7fHTP4V7Jz\n",
            "To: /content/DatasetHandler.py\n",
            "100%|██████████| 9.93k/9.93k [00:00<00:00, 10.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DatasetHandler.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# File Upload\n",
        "import gdown\n",
        "url_classifier = \"https://drive.google.com/file/d/1BY_YU4GvG8HFMfXgldeVx0aDTch0lhv5/view?usp=sharing\"\n",
        "url_datasethandler = \"https://drive.google.com/file/d/1BtSUZ6sZJze1uO-lMZ07jp7fHTP4V7Jz/view?usp=sharing\"\n",
        "\n",
        "output1 = \"CNN_Classifier.py\"\n",
        "output2 = \"DatasetHandler.py\"\n",
        "\n",
        "#gdown.download(url=url_classifier, output=output1, quiet=False, fuzzy=True)\n",
        "#gdown.download(url=url_datasethandler, output=output2, quiet=False, fuzzy=True)"
      ],
      "id": "BI83G32E0kE8"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "f3ff830c-9766-473d-984a-a67f30b89caa"
      },
      "outputs": [],
      "source": [
        "TRAIN = True"
      ],
      "id": "f3ff830c-9766-473d-984a-a67f30b89caa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6be422c0-7fb2-4f66-835f-a3921c0ea022"
      },
      "source": [
        "**Settings**"
      ],
      "id": "6be422c0-7fb2-4f66-835f-a3921c0ea022"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5bf1f7e0-9c7d-4a43-b75a-934df349cded"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10  # previous 30\n",
        "BATCH_SIZE = 16 # perlu di modif tidak?"
      ],
      "id": "5bf1f7e0-9c7d-4a43-b75a-934df349cded"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgOqcIQUfkg9"
      },
      "source": [
        "Install Library yang belum ada di Collabs"
      ],
      "id": "SgOqcIQUfkg9"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B4mxFNm3p38D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f08b08-959b-4d5b-e286-8b105153bdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 287 kB/s \n",
            "\u001b[?25hCollecting affine\n",
            "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.6)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.4.0)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.8)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.10 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio"
      ],
      "id": "B4mxFNm3p38D"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gentle-circulation"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "id": "gentle-circulation"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "burning-likelihood"
      },
      "source": [
        "# Load dataset\n",
        "\n",
        "The dataset is handeled by the class *DatasetHandler*."
      ],
      "id": "burning-likelihood"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Lz_rN7IYpl_h"
      },
      "outputs": [],
      "source": [
        "!python DatasetHandler.py\n",
        "!python CNN_Classifier.py"
      ],
      "id": "Lz_rN7IYpl_h"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dying-capacity"
      },
      "outputs": [],
      "source": [
        "from DatasetHandler import DatasetHandler\n",
        "training_handler = DatasetHandler('dataset/training')\n",
        "validation_handler = DatasetHandler('dataset/validation')"
      ],
      "id": "dying-capacity"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "filled-fluid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d56329-ebfd-4d62-e3f2-69a961fb0b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset classes\n",
            "\t dataset/training/sentinel2/city\n",
            "\t dataset/training/sentinel2/coastline\n",
            "\t dataset/training/sentinel2/lake\n",
            "\t dataset/training/sentinel2/river\n",
            "\t dataset/training/sentinel2/vegetation\n",
            "Dataset dimension\n",
            "\t 450 training samples belonging to  5 classes\n",
            "\t 50 validation samples belonging to  5 classes\n"
          ]
        }
      ],
      "source": [
        "print('Dataset classes')\n",
        "for c in training_handler.classes: print('\\t', c) #method .classes untuk ??\n",
        "\n",
        "print('Dataset dimension')\n",
        "print('\\t', len(training_handler.s2_paths), 'training samples belonging to ', len(training_handler.classes), 'classes')\n",
        "print('\\t', len(validation_handler.s2_paths), 'validation samples belonging to ', len(validation_handler.classes), 'classes')"
      ],
      "id": "filled-fluid"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "collaborative-cliff"
      },
      "outputs": [],
      "source": [
        "classes = []\n",
        "for c in training_handler.classes:\n",
        "    classes.append(c.split('/')[-1])"
      ],
      "id": "collaborative-cliff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "varied-ground"
      },
      "source": [
        "# Sentinel-2 classifier\n",
        "\n",
        "![](imgs/sen2.png)"
      ],
      "id": "varied-ground"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "impaired-retirement",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41e9f50-958e-4331-bbca-1adf310c16f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from CNN_Classifier import CNN_Classifier\n",
        "s2classifier = CNN_Classifier((64,64, 12), 5)"
      ],
      "id": "impaired-retirement"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "6d620b92-7ef2-431d-8297-39a477ebb419",
        "outputId": "05b81458-6806-4fd7-b9db-8ff21d69fd2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1800/1800 [==============================] - 2865s 2s/step - loss: 0.3364 - accuracy: 0.6419 - val_loss: 0.3009 - val_accuracy: 0.7428\n",
            "Epoch 2/10\n",
            "1800/1800 [==============================] - 2886s 2s/step - loss: 0.2269 - accuracy: 0.7914 - val_loss: 0.3309 - val_accuracy: 0.6841\n",
            "Epoch 3/10\n",
            "1800/1800 [==============================] - 2849s 2s/step - loss: 0.1978 - accuracy: 0.8258 - val_loss: 0.3949 - val_accuracy: 0.7138\n",
            "Epoch 4/10\n",
            " 634/1800 [=========>....................] - ETA: 27:44 - loss: 0.1800 - accuracy: 0.8377"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5ce633d3b3e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms2_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0ms2classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0ms2classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/S2-classifier.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CNN_Classifier.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, epochs, batch_size, train_data_generator, val_data_generator, training_steps, validation_steps)\u001b[0m\n\u001b[1;32m     54\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                 \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                             )\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if TRAIN == True:\n",
        "    batch_size = BATCH_SIZE\n",
        "    training_loader = training_handler.s2_data_loader(batch_size, (64,64,12))\n",
        "    validation_loader = validation_handler.s2_data_loader(batch_size, (64,64,12))\n",
        "    training_steps = 4*len(training_handler.s2_paths)\n",
        "    validation_steps = 4*len(validation_handler.s2_paths)\n",
        "    epochs = EPOCHS\n",
        "    s2classifier.train_model(epochs, batch_size, training_loader, validation_loader, training_steps, validation_steps)\n",
        "    s2classifier.model.save('weights/S2-classifier.h5')\n",
        "else:\n",
        "    s2classifier.model = load_model('weights/S2-classifier.h5')"
      ],
      "id": "6d620b92-7ef2-431d-8297-39a477ebb419"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quantitative-alcohol"
      },
      "source": [
        "# Sentinel-1 Classifier \n",
        "\n",
        "![](imgs/sen1.png)"
      ],
      "id": "quantitative-alcohol"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bottom-congress"
      },
      "outputs": [],
      "source": [
        "from CNN_Classifier import CNN_Classifier\n",
        "s1classifier = CNN_Classifier((64,64, 2), 5)"
      ],
      "id": "bottom-congress"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d82ba98-ad37-4215-a386-f2cdc92e9083"
      },
      "outputs": [],
      "source": [
        "if TRAIN == True:\n",
        "    training_handler = DatasetHandler('dataset/training')\n",
        "    validation_handler = DatasetHandler('dataset/validation')\n",
        "    batch_size = BATCH_SIZE\n",
        "    training_loader = training_handler.s1_data_loader(batch_size, (64,64,2))\n",
        "    validation_loader = validation_handler.s1_data_loader(batch_size, (64,64,2))\n",
        "    training_steps = 4*len(training_handler.s1_paths)\n",
        "    validation_steps = 4*len(validation_handler.s1_paths)\n",
        "    epochs = EPOCHS\n",
        "    s1classifier.train_model(epochs, batch_size, training_loader, validation_loader, training_steps, validation_steps)\n",
        "    s1classifier.model.save('weights/S1-classifier.h5')\n",
        "else:\n",
        "    s1classifier.model = load_model('weights/S1-classifier.h5')"
      ],
      "id": "7d82ba98-ad37-4215-a386-f2cdc92e9083"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbeb4ec3-6d39-48df-b794-bdad4f3fa7f0"
      },
      "source": [
        "# Late Fusion\n",
        "\n",
        "![](imgs/late-fusion.png)"
      ],
      "id": "bbeb4ec3-6d39-48df-b794-bdad4f3fa7f0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31bc509d-2355-4063-9841-cbb9b9fb722c"
      },
      "outputs": [],
      "source": [
        "s2classifier = CNN_Classifier((64,64, 12), 5)\n",
        "s1classifier = CNN_Classifier((64,64, 2), 5)\n",
        "s2classifier.model = load_model('weights/S2-classifier.h5')\n",
        "s1classifier.model = load_model('weights/S1-classifier.h5')"
      ],
      "id": "31bc509d-2355-4063-9841-cbb9b9fb722c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07bec00a-2648-4027-9432-3e80523e0c51"
      },
      "outputs": [],
      "source": [
        "validation_loader = validation_handler.s2_s1_data_loader(10*len(validation_handler.s1_paths), (64,64,12), (64,64,2))\n",
        "s2_s1, g_truth = next(iter(validation_loader))\n",
        "s2_pre = s2classifier.model.predict(s2_s1[0])\n",
        "s1_pre = s1classifier.model.predict(s2_s1[1])"
      ],
      "id": "07bec00a-2648-4027-9432-3e80523e0c51"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c705f1bd-c48c-49f6-bb4a-022cd836dc96"
      },
      "source": [
        "## Mean Late Fusion"
      ],
      "id": "c705f1bd-c48c-49f6-bb4a-022cd836dc96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23badf92-922d-46f3-8182-547c5c75660a"
      },
      "outputs": [],
      "source": [
        "late_sum = []\n",
        "for i in range(s2_pre.shape[0]):\n",
        "        late_sum.append(np.argmax((s1_pre[i]+s2_pre[i])))"
      ],
      "id": "23badf92-922d-46f3-8182-547c5c75660a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cc2a110-0e2e-4258-9184-51252a388058"
      },
      "source": [
        "## Weighted Late Fusion"
      ],
      "id": "5cc2a110-0e2e-4258-9184-51252a388058"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "501c31d5-619a-43bd-882f-eec296037c42"
      },
      "outputs": [],
      "source": [
        "late_weight = []\n",
        "w1 = np.array([0, 1, 1, 1, 0])\n",
        "w2 = 1 - w1\n",
        "\n",
        "for i in range(s2_pre.shape[0]):\n",
        "        late_weight.append(np.argmax((w1*s1_pre[i]+w2*s2_pre[i])))"
      ],
      "id": "501c31d5-619a-43bd-882f-eec296037c42"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dedicated-closing"
      },
      "source": [
        "# Results"
      ],
      "id": "dedicated-closing"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Experimen-Present-3.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}